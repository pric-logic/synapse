"""
Gemini Client Utility
Provides a clean interface for interacting with Google's Gemini API
"""

import google.generativeai as genai
from typing import Dict, List, Any, Optional, Union
import base64
import io
from PIL import Image
import time
import logging

from config import config

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiClient:
    """Client for interacting with Google's Gemini API"""
    
    def __init__(self):
        """Initialize Gemini client"""
        if not config.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY not configured")
        
        # Configure Gemini
        genai.configure(api_key=config.GEMINI_API_KEY)
        
        # Initialize models
        self.text_model = genai.GenerativeModel(
            model_name=config.GEMINI_MODEL,
            safety_settings=config.GEMINI_SAFETY_SETTINGS
        )
        
        # For multimodal tasks, use gemini-1.5-pro if available
        try:
            self.multimodal_model = genai.GenerativeModel(
                model_name="gemini-1.5-pro",
                safety_settings=config.GEMINI_SAFETY_SETTINGS
            )
        except Exception as e:
            logger.warning(f"Could not initialize multimodal model: {e}")
            self.multimodal_model = self.text_model
        
        logger.info(f"âœ… Gemini client initialized with model: {config.GEMINI_MODEL}")
    
    def generate_text(self, prompt: str, temperature: float = 0.1, max_tokens: int = 1000) -> str:
        """
        Generate text using Gemini
        
        Args:
            prompt: Text prompt
            temperature: Creativity level (0.0 to 1.0)
            max_tokens: Maximum tokens to generate
            
        Returns:
            Generated text
        """
        try:
            start_time = time.time()
            
            response = self.text_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                )
            )
            
            generation_time = time.time() - start_time
            logger.info(f"Text generation completed in {generation_time:.3f}s")
            
            if response.text:
                return response.text.strip()
            else:
                logger.warning("Empty response from Gemini")
                return "No response generated"
                
        except Exception as e:
            logger.error(f"Error generating text: {e}")
            return f"Error in text generation: {str(e)}"
    
    def generate_text_with_system_prompt(self, system_prompt: str, user_prompt: str, 
                                       temperature: float = 0.1, max_tokens: int = 1000) -> str:
        """
        Generate text with system and user prompts
        
        Args:
            system_prompt: System instruction
            user_prompt: User request
            temperature: Creativity level
            max_tokens: Maximum tokens to generate
            
        Returns:
            Generated text
        """
        full_prompt = f"{system_prompt}\n\nUser: {user_prompt}\n\nAssistant:"
        return self.generate_text(full_prompt, temperature, max_tokens)
    
    def analyze_image(self, image_path: str, prompt: str, temperature: float = 0.1) -> str:
        """
        Analyze image using Gemini multimodal capabilities
        
        Args:
            image_path: Path to image file
            prompt: Analysis prompt
            temperature: Creativity level
            
        Returns:
            Analysis result
        """
        try:
            # Load and prepare image
            image = Image.open(image_path)
            
            # Convert to bytes for Gemini
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()
            
            # Generate content with image
            response = self.multimodal_model.generate_content(
                [prompt, {"mime_type": "image/png", "data": img_byte_arr}],
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=1000,
                )
            )
            
            if response.text:
                return response.text.strip()
            else:
                return "No analysis generated"
                
        except Exception as e:
            logger.error(f"Error analyzing image: {e}")
            return f"Error in image analysis: {str(e)}"
    
    def analyze_image_from_base64(self, base64_image: str, prompt: str, 
                                 temperature: float = 0.1) -> str:
        """
        Analyze image from base64 string
        
        Args:
            base64_image: Base64 encoded image
            prompt: Analysis prompt
            temperature: Creativity level
            
        Returns:
            Analysis result
        """
        try:
            # Decode base64 image
            image_data = base64.b64decode(base64_image)
            
            # Generate content with image
            response = self.multimodal_model.generate_content(
                [prompt, {"mime_type": "image/png", "data": image_data}],
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=1000,
                )
            )
            
            if response.text:
                return response.text.strip()
            else:
                return "No analysis generated"
                
        except Exception as e:
            logger.error(f"Error analyzing base64 image: {e}")
            return f"Error in image analysis: {str(e)}"
    
    def chat_conversation(self, messages: List[Dict[str, str]], 
                         temperature: float = 0.1, max_tokens: int = 1000) -> str:
        """
        Have a conversation with Gemini
        
        Args:
            messages: List of message dictionaries with 'role' and 'content'
            temperature: Creativity level
            max_tokens: Maximum tokens to generate
            
        Returns:
            Response from Gemini
        """
        try:
            # Convert messages to Gemini format
            gemini_messages = []
            for msg in messages:
                if msg['role'] == 'user':
                    gemini_messages.append(msg['content'])
                elif msg['role'] == 'assistant':
                    gemini_messages.append(msg['content'])
            
            # Generate response
            response = self.text_model.generate_content(
                gemini_messages,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                )
            )
            
            if response.text:
                return response.text.strip()
            else:
                return "No response generated"
                
        except Exception as e:
            logger.error(f"Error in chat conversation: {e}")
            return f"Error in conversation: {str(e)}"
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about available models"""
        try:
            models = genai.list_models()
            return {
                "available_models": [model.name for model in models],
                "current_model": config.GEMINI_MODEL,
                "multimodal_support": self.multimodal_model != self.text_model
            }
        except Exception as e:
            logger.error(f"Error getting model info: {e}")
            return {"error": str(e)}
    
    def health_check(self) -> bool:
        """Check if Gemini API is accessible"""
        try:
            # Simple test generation
            response = self.text_model.generate_content("Hello", max_tokens=10)
            return response.text is not None
        except Exception as e:
            logger.error(f"Gemini health check failed: {e}")
            return False

# Global Gemini client instance
gemini_client: Optional[GeminiClient] = None

def get_gemini_client() -> GeminiClient:
    """Get or create Gemini client instance"""
    global gemini_client
    if gemini_client is None:
        gemini_client = GeminiClient()
    return gemini_client
